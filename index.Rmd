---
title: "The sound of COVID-19"
subtitle: "Analysis"
author: "Michael Okyere"
date: "Block 4, 2021"
#output: html_document
output: 
  flexdashboard::flex_dashboard:
    storyboard: true
    #theme: darkly
    theme: flatly
    #vertical layout: fill
    logo: icons/logoMO.png
    favicon: icons/logoMOB.png
    source_code: "https://github.com/mic-oky/cmpmusportfolio"
    target: _blank
    #social: [ "linkedin" ]
    css: custom-styles.css
#runtime: shiny
---

<!-- Thanks for stopping by at my Computational Musicology Portfolio! Beware, the code is pretty messy at this point. -->

```{r setup, include=FALSE}
set.seed(0)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = T)

library(tidyverse)
library(dplyr)
library(spotifyr)
library(ggplot2)
library(compmus)
library(plotly)
library(reshape2)
library(crosstalk)
library(d3scatter)
library(grid)
library(gridExtra)
library(ggrepel)
library(htmlwidgets)
library(slickR)
library(svglite)
library(DT)
library(stringi)
library(tidymodels)
library(ggdendro)
library(heatmaply)

library(flexdashboard)
library(shinydashboard)
library(shiny)

library(patchwork)

Sys.setlocale(category = "LC_ALL", locale = "English_United States.1252")
options(scipen = 999, encoding = "UTF-8")
```

<!-- Code for corpus -->

```{r Create Corpus, include=FALSE, cache=TRUE}
#Read filenames of csv's
files <- list.files(path="csvPlaylists/", pattern="week+.*csv")

#Create list of data frame per week without the ".csv" part 
weeks <- substr(files,1,nchar(files)-4)
featuresweeks <- paste0("features", substr(files,1,nchar(files)-4))

#Load all files in a loop using weeks data frame. 
#(I wish I new about purrr a little bit earlier... but this gets the job done)
for(i in weeks){
    filepath <- file.path("csvPlaylists",paste(i,".csv",sep=""))
    #assign csv to variable df
    df <- read.csv(filepath)
    #df <- read_csv(filepath)
    
    #clean data frame: remove header, set 1st row as header, remove 1st row
    names(df) <- NULL 
    names(df) <- df[1,] 
    
    #Create year and week variables and assign week and year to playlist
    df$year[i] <- str_sub(i, -4)
    df$week[i] <- str_remove(substr(i,1,nchar(i)-5), "week")

    #Remove 1st row (NA's)    
    df <- df[-1,]    
    
    #Select first 50 values (Top 50) of df 
    df <- head(df,50)
    
    #Loop-in-loop: for each week in df #Nested-loop: code takes a long time to run (again purrr...)
    for(j in df){
        #Set variables to correct datatype
        df$Position <- as.integer(as.character(df$Position))
        df$Streams <- as.integer(as.character(df$Streams))
        #Extract Spotify URI from URL
        df$URI <- str_replace(df$URL, "https://open.spotify.com/track/", "")
        
        #Create variable "week*_20**" and assign current df
        assign(paste0("", i), df)
        #Create variable "featuresweek*_20**" and assign Spotify audiofeatures
        assign(paste0("features", i),cbind(get_track_audio_features(df$URI), 
                                           year = str_sub(i, -4),
                                           week = str_remove(substr(i,1,nchar(i)-5), "week"))
               )
      
    }

}
```

```{r Data Wrangling, include=FALSE}
#Splitting all weeks to their respective dataframe
weeks2021 <- weeks[grep("^week.*_2021$", weeks)]
weeks2020 <- weeks[grep("^week.*_2020$", weeks)]
weeks2019 <- weeks[grep("^week.*_2019$", weeks)]
fweeks2021 <- featuresweeks[grep("^featuresweek.*_2021$", featuresweeks)]
fweeks2020 <- featuresweeks[grep("^featuresweek.*_2020$", featuresweeks)]
fweeks2019 <- featuresweeks[grep("^featuresweek.*_2019$", featuresweeks)]

#Sorting all weeks chronologically
as.numeric(gsub('^week([0123456789]*)\\_2021$','\\1',weeks2021))->sort2021
sorted_weeks2021 <- weeks2021[order(sort2021)]
sorted_fweeks2021 <- fweeks2021[order(sort2021)]

as.numeric(gsub('^week([0123456789]*)\\_2020$','\\1',weeks2020))->sort2020
sorted_weeks2020 <- weeks2020[order(sort2020)]
sorted_fweeks2020 <- fweeks2020[order(sort2020)]

as.numeric(gsub('^week([0123456789]*)\\_2019$','\\1',weeks2019))->sort2019
sorted_weeks2019 <- weeks2019[order(sort2019)]
sorted_fweeks2019 <- fweeks2019[order(sort2019)]
```

```{r Summarizing features, include=FALSE, cache=TRUE}
summary2019 = list()
summary2020 = list()
summary2021 = list()
fsummary2019 = list()
fsummary2020 = list()
fsummary2021 = list()

# Extracting featuredata from sorted list
for(l in sorted_fweeks2019){
    dat <- get(l) %>%
        summarize(mean_dance = mean(danceability),
                  mean_energy = mean(energy),
                  mean_key = mean(key),
                  mean_loudness = mean(loudness),
                  mean_mode = mean(mode),
                  mean_speechiness = mean(speechiness),
                  mean_acousticness = mean(acousticness),
                  mean_instrumentalness = mean(instrumentalness),
                  mean_liveness = mean(liveness),
                  mean_valence = mean(valence),
                  mean_tempo = mean(tempo),
                  mean_duration_minute = mean(duration_ms/1000/60),
                  year = max(year)
                  )
    fsummary2019[[l]] <- dat 
}

for(l in sorted_fweeks2020){
    dat <- get(l) %>%
        summarize(mean_dance = mean(danceability),
                  mean_energy = mean(energy),
                  mean_key = mean(key),
                  mean_loudness = mean(loudness),
                  mean_mode = mean(mode),
                  mean_speechiness = mean(speechiness),
                  mean_acousticness = mean(acousticness),
                  mean_instrumentalness = mean(instrumentalness),
                  mean_liveness = mean(liveness),
                  mean_valence = mean(valence),
                  mean_tempo = mean(tempo),
                  mean_duration_minute = mean(duration_ms/1000/60),
                  year = max(year))
    fsummary2020[[l]] <- dat 
}

for(l in sorted_fweeks2021){
    dat <- get(l) %>%
        summarize(mean_dance = mean(danceability),
                  mean_energy = mean(energy),
                  mean_key = mean(key),
                  mean_loudness = mean(loudness),
                  mean_mode = mean(mode),
                  mean_speechiness = mean(speechiness),
                  mean_acousticness = mean(acousticness),
                  mean_instrumentalness = mean(instrumentalness),
                  mean_liveness = mean(liveness),
                  mean_valence = mean(valence),
                  mean_tempo = mean(tempo),
                  mean_duration_minute = mean(duration_ms/1000/60),
                  year = max(year))
    fsummary2021[[l]] <- dat 
}

# Extracting low-level top track data from sorted list
for(l in sorted_weeks2019){
    dat <- get(l) %>%
        summarize(mean_streams = mean(Streams),
                  min_streams = min(Streams),
                  max_streams = max(Streams),
                  top_track = head(paste(`Track Name`,"-" , Artist), 1)
                  )
    summary2019[[l]] <- dat
}

for(l in sorted_weeks2020){
    dat <- get(l) %>%
        summarize(mean_streams = mean(Streams),
                  min_streams = min(Streams),
                  max_streams = max(Streams),
                  top_track = head(paste(`Track Name`,"-" , Artist), 1)
                  )
    summary2020[[l]] <- dat
}

for(l in sorted_weeks2021){
    dat <- get(l) %>%
        summarize(mean_streams = mean(Streams),
                  min_streams = min(Streams),
                  max_streams = max(Streams),
                  top_track = head(paste(`Track Name`,"-" , Artist), 1)
                  )
    summary2021[[l]] <- dat
}

# Binding rows 
fdata2019 <- dplyr::bind_rows(fsummary2019)
fdata2020 <- dplyr::bind_rows(fsummary2020)
fdata2021 <- dplyr::bind_rows(fsummary2021)
sdata2019 <- dplyr::bind_rows(summary2019)
sdata2020 <- dplyr::bind_rows(summary2020)
sdata2021 <- dplyr::bind_rows(summary2021)


data2019 <- cbind(week_year = str_remove(sorted_weeks2019, "_2019"),fdata2019, sdata2019)
data2020 <- cbind(week_year = str_remove(sorted_weeks2020, "_2020"),fdata2020, sdata2020)
data2021 <- cbind(week_year = str_remove(sorted_weeks2021, "_2021"),fdata2021, sdata2021)

dataAll <- dplyr::bind_rows(data2019, data2020, data2021)

# Add pandemic label
dataAll <- dataAll %>%
  mutate(pandemic = case_when(
    year == 2019 ~ "Before COVID-19",
    year == 2020 & week_year == week_year[53:60]  ~ "Before COVID-19",
    TRUE ~ "During COVID-19")
  )

```

```{r Full features, include = FALSE, cache=TRUE}
all2019f = list()
all2019 = list()
all2020f = list()
all2020 = list()
all2021f = list()
all2021 = list()

for(m in sorted_fweeks2019){
    datm <- get(m) %>%
        summarize(danceability,energy,key,loudness,mode,speechiness,acousticness,instrumentalness,
                  liveness,valence,tempo,duration_minute = duration_ms/1000/60, year, week = as.factor(week),
                  track.uri = uri,
                  mean_dance = mean(danceability),
                  mean_energy = mean(energy),
                  mean_key = mean(key),
                  mean_loudness = mean(loudness),
                  mean_mode = mean(mode),
                  mean_speechiness = mean(speechiness),
                  mean_acousticness = mean(acousticness),
                  mean_instrumentalness = mean(instrumentalness),
                  mean_liveness = mean(liveness),
                  mean_valence = mean(valence),
                  mean_tempo = mean(tempo),
                  mean_duration_minute = mean(duration_ms/1000/60))
    all2019f[[m]] <- datm
}

for(o in sorted_weeks2019){
    dat <- get(o) %>%
        summarize(Position, Streams, `Track Name`, Artist, Streams, year, week,
                  mean_streams = mean(Streams),
                  min_streams = min(Streams),
                  max_streams = max(Streams),
                  top_track = head(paste(`Track Name`,"-" , Artist), 1)
                  )
    all2019[[o]] <- dat
}

for(m in sorted_fweeks2020){
    datm <- get(m) %>%
        summarize(danceability,energy,key,loudness,mode,speechiness,acousticness,instrumentalness,
                  liveness,valence,tempo,duration_minute = duration_ms/1000/60, year, week = as.factor(week),
                  track.uri = uri,
                  mean_dance = mean(danceability),
                  mean_energy = mean(energy),
                  mean_key = mean(key),
                  mean_loudness = mean(loudness),
                  mean_mode = mean(mode),
                  mean_speechiness = mean(speechiness),
                  mean_acousticness = mean(acousticness),
                  mean_instrumentalness = mean(instrumentalness),
                  mean_liveness = mean(liveness),
                  mean_valence = mean(valence),
                  mean_tempo = mean(tempo),
                  mean_duration_minute = mean(duration_ms/1000/60))
    all2020f[[m]] <- datm
}

for(o in sorted_weeks2020){
    dat <- get(o) %>%
        summarize(Position, Streams, `Track Name`, Artist, Streams, year, week,
                  mean_streams = mean(Streams),
                  min_streams = min(Streams),
                  max_streams = max(Streams),
                  top_track = head(paste(`Track Name`,"-" , Artist), 1)
                  )
    all2020[[o]] <- dat
}

for(m in sorted_fweeks2021){
    datm <- get(m) %>%
        summarize(danceability,energy,key,loudness,mode,speechiness,acousticness,instrumentalness,
                  liveness,valence,tempo,duration_minute = duration_ms/1000/60, year, week = as.factor(week),
                  track.uri = uri,
                  mean_dance = mean(danceability),
                  mean_energy = mean(energy),
                  mean_key = mean(key),
                  mean_loudness = mean(loudness),
                  mean_mode = mean(mode),
                  mean_speechiness = mean(speechiness),
                  mean_acousticness = mean(acousticness),
                  mean_instrumentalness = mean(instrumentalness),
                  mean_liveness = mean(liveness),
                  mean_valence = mean(valence),
                  mean_tempo = mean(tempo),
                  mean_duration_minute = mean(duration_ms/1000/60))
    all2021f[[m]] <- datm
}

for(o in sorted_weeks2021){
    dat <- get(o) %>%
        summarize(Position, Streams, `Track Name`, Artist, Streams, year, week,
                  mean_streams = mean(Streams),
                  min_streams = min(Streams),
                  max_streams = max(Streams),
                  top_track = head(paste(`Track Name`,"-" , Artist), 1)
                  )
    all2021[[o]] <- dat
}

big_all2019f <- dplyr::bind_rows(all2019f)
big_all2019 <- dplyr::bind_rows(all2019)

big_all2020f <- dplyr::bind_rows(all2020f)
big_all2020 <- dplyr::bind_rows(all2020)

big_all2021f <- dplyr::bind_rows(all2021f)
big_all2021 <- dplyr::bind_rows(all2021)

join_big2019 <- dplyr::bind_cols(big_all2019f, big_all2019)
join_big2020 <- dplyr::bind_cols(big_all2020f, big_all2020)
join_big2021 <- dplyr::bind_cols(big_all2021f, big_all2021)

corpus_df <- dplyr::bind_rows(join_big2019,join_big2020,join_big2021)
corpus_df <- corpus_df %>% 
  rename(year = year...13, week = week...14) %>%
  # Delete duplicate year and week columns
  select(-c(year...32, week...33)) %>%
  mutate(week_n = as.numeric(week)) %>%
  mutate(pandemic = case_when(
    year == 2019 ~ "Before COVID-19",
    year == 2020 & week_n == c(1:8) ~ "Before COVID-19",
    year == 2020 & week_n != c(1:8) ~ "During COVID-19",
    year == 2021 ~ "During COVID-19")
    )
corpus_df <- corpus_df %>% group_by(track.uri) %>% mutate(n_weeks_corpus = n())
corpus_df <- corpus_df %>% ungroup()

corpus_top25 <- corpus_df %>% filter(Position == c(1:2))
```

```{r COVID-19 dataset, include = FALSE}
# Read COVID-CSV
covid_dat_2020 <- read.csv("csvCOVID/COVID-19_2020.csv", header = TRUE, sep = ";")
covid_dat_2021 <- read.csv("csvCOVID/COVID-19_2021.csv", header = TRUE, sep = ";")

# Create zero dataframe for 2019 (Since no COVID data available from RIVM till Feb 2020)
covid_dat_2019 <- data.frame(#week = c(45:52),
                             week = c(1:52),
                             hospital_admission = c(0),
                             cum_hospital_admission = c(0),
                             deceased = c(0),
                             cum_deceased = c(0),
                             total_reported = c(0),
                             cum_total_reported = c(0)
                             )

# Rename weeknumbers to indicate year + factor weeks to avoid grouping by week
covid_dat_2019y <- covid_dat_2019
covid_dat_2019y$week_year <- paste0(covid_dat_2019$week, "_2019")
covid_dat_2019y$week_year <- factor(covid_dat_2019y$week_year, levels = covid_dat_2019y$week_year)

covid_dat_2019y$week <- factor(covid_dat_2019y$week, levels = covid_dat_2019y$week)
covid_dat_2019y$year <- 2019


covid_dat_2020y <- covid_dat_2020
covid_dat_2020y$week_year <- paste0(covid_dat_2020$week, "_2020")
covid_dat_2020y$week_year <- factor(covid_dat_2020y$week_year, levels = covid_dat_2020y$week_year)

covid_dat_2020y$week <- factor(covid_dat_2020y$week, levels = covid_dat_2020y$week)
covid_dat_2020y$year <- 2020


covid_dat_2021y <- covid_dat_2021
covid_dat_2021y$week_year <- paste0(covid_dat_2021$week, "_2021")
covid_dat_2021y$week_year <- factor(covid_dat_2021y$week_year, levels = covid_dat_2021y$week_year)

covid_dat_2021y$week <- factor(covid_dat_2021y$week, levels = covid_dat_2021y$week)
covid_dat_2021y$year <- 2021


# Combine dataframes + factor weeks to avoid grouping by week
covid_daty <- dplyr::bind_rows(covid_dat_2019y,covid_dat_2020y,covid_dat_2021y)
#covid_daty$week <- factor(covid_daty$week, levels = covid_daty$year)
covid_daty$week_year <- factor(covid_daty$week_year, levels = covid_daty$week_year)
#covid_daty$week <- as.character(covid_daty$week)
#covid_daty$week <- factor(covid_daty$week, ordered = is.ordered(covid_daty$week))

#comb_data <- dplyr::bind_rows(dataAll, covid_daty)
```

```{r Combining Datasets, include = FALSE}

#NOTE temporarily removed first column (weekXX), can rename later if needed, and added zero row for spotify week 7, will add later
#NOTE2 first column not very necessary as week_year and week are present already
#NOTE3 added week 7
#comb_data <- dplyr::bind_cols(rbind(dataAll[-1], 0), covid_daty)
comb_data <- dplyr::bind_cols(dataAll[-1], covid_daty)
comb_data <- tibble::rowid_to_column(comb_data, "ID")

# counting top_tracks weeks on number 1 spot
#toptraxweekly <- as.data.frame((comb_data$top_track$week_year) , stringsAsFactors = F)
toptraxweekly <- as.data.frame((comb_data %>% select(top_track, week_year, max_streams)) , stringsAsFactors = F)
toptraxcount <- comb_data %>% count(top_track)
toptraxtotstreams <- comb_data %>% group_by(top_track) %>% summarise(tot_streams = sum(max_streams))
traxjoin <- left_join(toptraxweekly, toptraxcount)
traxjoin <- left_join(traxjoin, toptraxtotstreams)

comb_data_trax <- left_join(comb_data, traxjoin)
```

```{r chordogram, include = FALSE}
circshift <- function(v, n) {
  if (n == 0) v else c(tail(v, n), head(v, -n))
}

#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
```

```{r, include = FALSE}
get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit %>% 
    collect_predictions() %>% 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit %>% 
    conf_mat_resampled() %>% 
    group_by(Prediction) %>% mutate(precision = Freq / sum(Freq)) %>% 
    group_by(Truth) %>% mutate(recall = Freq / sum(Freq)) %>% 
    ungroup() %>% filter(Prediction == Truth) %>% 
    select(class = Prediction, precision, recall)
}  
```

<!-- Code for dashboard -->

<!-- Page 1 (additional pages (optional) can add extra frames) -->

<!-- Frame 1 -->

### 1. **Did Spotify users in the Netherlands change their music listening behavior during the COVID-19 pandemic?**{data-commentary-width=500} 

<h4>The sound of COVID-19: Spotify usage in the Netherlands during a pandemic</h4>

The COVID-19 pandemic has stirred society up by quite large margin. Many people are (in)directly affected by the health crisis or the resulting governmental measures.
This led to adjustments, e.g. social distancing and isolation, causing society to change communication, work and more aspects of daily life. This dashboard will explore the following:

> Did Spotify users in the Netherlands change their music listening behavior during the COVID-19 pandemic?

A corpus has been created in order to perform various computational musicological analyses using the [spotifyr](https://www.rcharlie.com/spotifyr/){target="_blank"} and [compmus](https://jaburgoyne.github.io/compmus/){target="_blank"} packages.

The general listening behavior of Spotify users in the Netherlands before and during the pandemic will be explored, as measured by the Spotify API. In addition, specific events related to the pandemic (e.g. lockdown and curfew) will be considered as well to find to what extent possible changes in listening behavior can be attributed to these events.

<h4>Corpus</h4>

In order to analyze general listening behavior, the most important variables for the portfolio are:

- Playlist
- Spotify Audio Features
- Time
- [COVID-19 variables provided by RIVM (The Dutch National Institute for Public Health and the Environment)](https://data.rivm.nl/covid-19/){target="_blank"}

***

```{js, echo = FALSE}
function hideShow() {
  var x = document.getElementById("divID");
  if (x.style.display === "none") {
    x.style.display = "block";
  } else {
    x.style.display = "none";
  }
}
```

<ul class="nav nav-tabs">
  <li class="nav-item">
    <a class="nav-link active" data-toggle="tab" href="#playlist">Playlist</a>
  </li>
  <li class="nav-item">
    <a class="nav-link" data-toggle="tab" href="#spotifyaudiofeatures">Audio Features</a>
  </li>
  <li class="nav-item">
    <a class="nav-link" data-toggle="tab" href="#time">Time</a>
  </li>
  <li class="nav-item">
    <a class="nav-link" data-toggle="tab" href="#covidvariables">COVID-19 Variables</a>
  </li>
</ul>

<div id="myTabContent" class="tab-content">
  <div class="tab-pane fade active in" id="playlist">
  
In order to keep track on the average listening behavior of Dutch Spotify users, the weekly ‘Top 50’ playlists from the Netherlands will be analyzed over time. The years 2019 (52 weeks) and 2020 (53 weeks) and will be measured in its entirety, and 2021 is measured until week 7.

2019 contains 52 playlists consisting of 50 tracks per playlist <br>
2020 contains 53 playlists consisting of 50 tracks per playlist<br>
2021 contains 7 playlists consisting of 50 tracks per playlist
Totaling 5600 observations/tracks.
As a track can be in the charts for multiple weeks, duplicates occur.
The number of *unique* tracks within the corpus is 826.

Since Spotify autoupdates their playlists, the historical 'Top 50' lists in the form of CSV files will be retrieved from [Spotify Charts](https://spotifycharts.com/regional/nl/weekly/latest){target="_blank"}.
  
  </div>
  <div class="tab-pane fade" id="spotifyaudiofeatures">

The changes of (or lack thereof) listening behavior will be measured by the the different Spotify Audio Features:

  <button class="btn2" onclick="hideShow()">Spotify Audio Features:</button>

  <div id="divID">
  
<details>
<summary>• danceability</summary>
Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.

</details>

<details>
<summary>• energy</summary>
Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale. Perceptual features contributing to this attribute include dynamic range, perceived loudness, timbre, onset rate, and general entropy.

</details>

<details>
<summary>• key</summary>
The key the track is in. Integers map to pitches using standard Pitch Class notation . E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on.

</details>

<details>
<summary>• loudness</summary>
The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks. Loudness is the quality of a sound that is the primary psychological correlate of physical strength (amplitude). Values typical range between -60 and 0 db.

</details>

<details>
<summary>• mode</summary>
Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.

</details>

<details>
<summary>• speechiness</summary>
Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.

</details>

<details>
<summary>• acousticness</summary>
A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic.

</details>

<details>
<summary>• instrumentalness</summary>
Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.

</details>

<details>
<summary>• liveness</summary>
Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.

</details>

<details>
<summary>• tempo</summary>
The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.

</details>

<details>
<summary>• valence</summary>
A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).

</details>

<details>
<summary>• duration_ms</summary>
The duration of the track in milliseconds.

</details>


Also the following variables obtained through the Spotify API will be included:

- Number of streams
- Position
- Track Name
- Artist
- Streams

  </div>

  </div>
  
  <div class="tab-pane fade" id="time">

The variable time will be used to identify the different weeks as well as the periods before and during the pandemic that may explain the changes in music listening behavior from the top and viral playlists.

In addition interesting annual periods will be isolated to see if similar patterns reoccur during the pandemic.
For example, the December Holiday season before and during the pandemic will be analyzed to identify whether Spotify users altered their Christmas related listening behavior.

- Week
- Year

The corpus measures from week 1, 2019 till week 7, 2021 and will split the data into two periods. A period *Before the pandemic* and *During the pandemic*. This will make it clearer to attribute analyses to these periods, rather than annually or weekly.

  </div>
  <div class="tab-pane fade" id="covidvariables">

Alongside the musical analyses, statistics concerning COVID-19 will be taken into account as well.
The used data is provided by the The Dutch National Institute for Public Health and the Environment (RIVM). The data has been pre-processed to include both weekly and cumulative data. The variables that are included in this dashboard are the following variables:

- Number Hospital Admissions
- Number of Deaths
- Reported cases of COVID-19

  </div>
</div>

<!-- Frame 2 -->

### 2. **COVID-19 & Music trends**: Music trends show **periodical pattern**, COVID-19 has **societal impact**. 

```{r, echo = FALSE}

comb_data.long <- melt(comb_data, id.vars = c("week", "year...27", "week_year", "max_streams", "min_streams", "mean_streams", "top_track", "total_reported", "deceased", "hospital_admission"), measure.vars = c("deceased", "hospital_admission"))

# comb_data.long <- melt(comb_data, id.vars = c("week", "year", "week_year", "max_streams", "min_streams", "mean_streams", "top_track"), measure.vars = c("deceased", "hospital_admission"))

coeff <- 1000

#p <- ggplot(comb_data.long, aes(x = week_year, label = max_streams, label2 = min_streams, label3 = top_track)) +
p <- ggplot(comb_data.long, aes(text = paste('Week, Year:', paste(week,"",year...27),
                                              '<br>Top Track:', top_track, 
                                              '<br>Max Streams:', max_streams,
                                              '<br>Average Streams:', mean_streams,
                                              '<br>Number Deceased:', deceased,
                                              '<br>Number Admitted:', hospital_admission,
                                              '<br>Number Confirmed Cases:', total_reported))) +
  geom_line(aes(x = factor(week_year), y = max_streams/coeff, group = 1, color = "Streams Top 1 track"),
            alpha = 0.7, size = 1) +
  geom_point(aes(x = week_year, y = max_streams/coeff, color = "Streams Top 1 track" ), group = 1, alpha = 1, size = 1) +
  geom_line(aes(x = factor(week_year), y = mean_streams/coeff, group = 2, color = "Average Streams of Top 50"),
            alpha = 0.7, size = 1) +
  geom_point(aes(x = week_year, y = mean_streams/coeff, color = "Average Streams of Top 50"), group = 2, alpha = 1, size = 1) +
  geom_bar(aes(x = week_year, y = value, fill = variable), stat = "identity") +
  
  geom_vline(xintercept = 64, linetype="dotted", size = 0.5, alpha = 0.5) +
    annotate("text", label = "<b>1st lockdown</b>\n'Intelligent'\nLockdown", x = 63, y = 4500, size = 3) +

  geom_vline(xintercept = 94, linetype="dotted", size = 0.5, alpha = 0.5) +
    annotate("text", label = "<b>2nd lockdown</b>\nPartial\nLockdown", x = 92, y = 4000, size = 3) +

  geom_vline(xintercept = 103, linetype="dotted", size = 0.5, alpha = 0.5) +
    annotate("text", label = "<b>3rd lockdown</b>\nHard\nLockdown", x = 101, y = 4500, size = 3) +

  geom_vline(xintercept = 107, linetype="dotted", size = 0.5, alpha = 0.5) +
    annotate("text", label = "Curfew", x = 105, y = 4000, size = 3) +

  scale_color_manual(name = "Variables", values = c("Streams Top 1 track" = "#33618d",
                                                    "Average Streams of Top 50" = "#440d57")) +
  
  scale_x_discrete(label=function(x){
    return(str_replace(x,"_20","\n'"))
    }) +
  
  scale_y_continuous(
    
    name = "Number of Hospitalized and Deceased\nNumber of Streams: Average & Top 1 Track (*1,000)",
    
    # Add a second axis and specify its features
    #sec.axis = sec_axis(trans = ~ . * coeff, name="Number of Streams of Top 1 track")
    expand = expansion(mult = c(0, 0))
  )+
  
   # scale_color_viridis_d(
   #  begin = 0,
   #  end = 0.3,
   #  option = "B",
   #  alpha = 0.75,
   #  guide = NULL,
   #  direction = 1
   #  ) +
  
  scale_fill_viridis_d(
    begin = 0.7,
    end = 0.9,
    option = "D",
    alpha = 0.75,
    guide = NULL,
    direction = -1,
    name = "Variables",
    labels = c("Deceased", "Hospital admissions")
    ) +
  
  theme_light() +
  labs(
    x = "Week, Year",
    title = "Spotify and Covid trends",
    subtitle = "Trends from 2019 to 2021"
  ) +

  theme(axis.title.y = element_text(size=13),
        axis.title.y.right = element_text(size=13),
        #axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)
        )


l1 <- list(
  source=base64enc::dataURI(file = "icons/House-lockdown (1).png"),
  x = 62.5, y = 1, sizex = 3, sizey = 0.05,
  xref = "x", yref = "paper",
  xanchor = "left", yanchor = "bottom"
  )
l2 <- list(
  source=base64enc::dataURI(file = "icons/House-lockdown (1).png"),
  x = 92.5, y = 1, sizex = 3, sizey = 0.05,
  xref = "x", yref = "paper",
  xanchor = "left", yanchor = "bottom"
  )
l3 <- list(
  source=base64enc::dataURI(file = "icons/House-lockdown (1).png"),
  x = 101.5, y = 1, sizex = 3, sizey = 0.05,
  xref = "x", yref = "paper",
  xanchor = "left", yanchor = "bottom"
  )
l3cf <- list(
  source=base64enc::dataURI(file = "icons/Time (1).png"),
  x = 105.5, y = 1, sizex = 3, sizey = 0.05,
  xref = "x", yref = "paper",
  xanchor = "left", yanchor = "bottom"
  )

p2_ly <- ggplotly(p, tooltip = "text", dynamicTicks = FALSE) %>%
  add_lines() %>%
  layout(legend = list(x = 1, y = 1)) %>%
  rangeslider(start = str_replace("45_2019","_20","\n'"), end = str_replace("6_2021","_20","\n'")) %>%
  rangeslider(start = 10, end = 113) %>%
  layout(images = list(l1,l2,l3,l3cf))

for (i in 1:length(p2_ly$x$data)){
    if (!is.null(p2_ly$x$data[[i]]$name)){
        p2_ly$x$data[[i]]$name =  gsub("\\(","",str_split(p2_ly$x$data[[i]]$name,",")[[1]][1])
    }
}

p2_ly

```


***

<ul class="nav nav-tabs">
  <li class="nav-item">
    <a class="nav-link active" data-toggle="tab" href="#covid">COVID</a>
  </li>
  <li class="nav-item">
    <a class="nav-link" data-toggle="tab" href="#outliers">Trends & Outliers</a>
  </li>
  <li class="nav-item">
    <a class="nav-link" data-toggle="tab" href="#conclusion">Conclusion</a>
  </li>
</ul>


<div id="myTabContent" class="tab-content">
  <div class="tab-pane fade active in" id="covid">

<h4>The first case(s)</h4>
On February 27th, 2020 (week 9), the first case of COVID-19 was confirmed in the Netherlands.
Before this occurrence (when everything was still normal) from week 4 in 2020, the streams of the top songs decreased. When the first COVID-19 cases, admissions and deaths were confirmed, the number continued to decline. Until the cases started to increase more rapidly. What caused this increase?

<h4>Togetherness and solidariy during lockdown</h4>
As the situation became more severe, with record COVID-related hospital admissions in week 13, the [Dutch government implemented the first lockdown: the 'intelligent' lockdown](https://en.wikipedia.org/wiki/COVID-19_pandemic_in_the_Netherlands){target="_blank"} (first dotted line). This led to relative high public solidarity towards those affected by the virus, especially essential workers en the elderly. This may explain the sudden spike of streams rising from 1,598,458 to a record 3,482,822 streams in weeks 13 and 14 in 2020. The song 17 Miljoen Mensen - Live @538 in Ahoy by Davina Michelle topped the charts for five consecutive weeks. This song [was dedicated to the people affected by the virus](https://www.ad.nl/show/davina-michelle-en-snelle-brengen-17-miljoen-mensen-uit~a9bdeb0e){target="_blank"}. So this spike is most likely related to the virus and its effects. Although during the 2nd and 3rd lockdown an increase in streams is shown as well, the measures may not be the cause as it is in line with the annual trend.
  
  </div>
  
  <div class="tab-pane fade" id="outliers">

<h4>Trends</h4>
Dutch Spotify users in general are fairly consistent, when it comes to streaming popular songs. Just looking at 2019, 2020 (and the first 7 few weeks of 2021), you can find a reoccurring pattern.Streams **increase during the first weeks followed by a sharp decline**. During summertime, streams **remain relatively stable**. And Streams **decrease before the holiday season, with a short spike on Christmas.** Showing therefore a 'procyclical' behavior, simply meaning that popular songs on average are correlated to a general trend (term repurposed from Economics).

<h4>Outliers</h4>
Not all Spotify users/songs follow the same trend. In some cases the status quo is defied a large margin. A couple of cases will be introduced that will be further analyzed.

<h5>Eurovision Song Contest</h5>
The most streamed song before the pandemic (also within the corpus) is *'Arcade'* by Duncan Laurence, with 5,473,513 streams in week 21, 2019. This is due to the song [winning the 2019 Eurovision Song Contest for the Netherlands](https://eurovision.tv/story/duncan-laurence-the-netherlands-wins-2019-eurovision-song-contest){target="_blank"}.

<h5>Corona</h5>
As mentioned earlier, the track *'17 Miljoen Mensen'* is also an outlier, but related to the pandemic. Another track that might be related is *'All I Want for Christmas Is You'* by Mariah Carey. As it was quite strange celebrating Christmas during a pandemic, people were streaming Christmas songs more and earlier in 2020 than in 2019.

  </div>
  
  <div class="tab-pane fade" id="conclusion">

So, in general the **popular songs in the Netherlands follow a periodic/cyclical trend.**

The **outliers** are caused by a large **societal impact**, as explained by the togetherness during the first wave of the pandemic, the Netherlands winning Eurovision and people listening to Christmas songs more and earlier.

At the same time, Dutch people 'recover' fairly quickly to the regular level. Second and third wave of COVID-19 and the related measures imposed by the Dutch government did not see similar impact as the first. Rather these followed similar pattern as in 2019.

***

<object data="https://open.spotify.com/embed/playlist/5JTGCV2ipF8P0ryLQ6r9jF" width="280" height="80">
    <embed src="https://open.spotify.com/embed/playlist/5JTGCV2ipF8P0ryLQ6r9jF" width="280" height="80"></embed>
    Error: Embedded data could not be displayed.
</object>

  </div>
</div>


<!-- Frame 3 -->

### 3. Trip down memory lane:<br>**Comparing pre-pandemic to intra-pandemic listening behavior**

```{r, echo = FALSE}
# all2019f = list()
# all2019 = list()
# 
# for(m in sorted_fweeks2019){
#     datm <- get(m) %>%
#         summarize(danceability,energy,key,loudness,mode,speechiness,acousticness,instrumentalness,
#                   liveness,valence,tempo,duration_minute = duration_ms/1000/60, year, week = as.factor(week),
#                   mean_dance = mean(danceability),
#                   mean_energy = mean(energy),
#                   mean_key = mean(key),
#                   mean_loudness = mean(loudness),
#                   mean_mode = mean(mode),
#                   mean_speechiness = mean(speechiness),
#                   mean_acousticness = mean(acousticness),
#                   mean_instrumentalness = mean(instrumentalness),
#                   mean_liveness = mean(liveness),
#                   mean_valence = mean(valence),
#                   mean_tempo = mean(tempo),
#                   mean_duration_minute = mean(duration_ms/1000/60))
#     all2019f[[m]] <- datm
# }
# 
# for(o in sorted_weeks2019){
#     dat <- get(o) %>%
#         summarize(Position, Streams, `Track Name`, Artist, Streams, year, week,
#                   mean_streams = mean(Streams),
#                   min_streams = min(Streams),
#                   max_streams = max(Streams),
#                   top_track = head(paste(`Track Name`,"-" , Artist), 1)
#                   )
#     all2019[[o]] <- dat
# }
# 
# 
# big_all2019f <- dplyr::bind_rows(all2019f)
# big_all2019 <- dplyr::bind_rows(all2019)
# 
# join_big2019 <- dplyr::bind_cols(big_all2019f, big_all2019)
# 
# #big_all2019 = do.call(rbind, all2019)


# sd_19 <- SharedData$new(join_big2019)
# fls <- filter_slider("ps", "Position", sd_19, "Position", step = 1)
# flc <- filter_checkbox(id = "wk", label = "Week", sharedData = sd_19, group = ~week...14, inline = TRUE)
# flc2 <- filter_checkbox(id = "md", label = "Mode", sharedData = sd_19, group = ~mode, inline = TRUE)
# 
# p1 <- ggplot(sd_19, aes(x = valence, y = energy, colour = week...14, label = `Track Name`, label2 = Artist)) +
#   #geom_point(aes(size = danceability, alpha = 0.4, fill = week...14)) + 
#   geom_point(aes(size = danceability, fill = week...14), alpha = 0.3) +  
#   theme_light() 
# p2 <- ggplot(sd_19, aes(x = week...14, y = valence, colour = week...14, label = `Track Name`, label2 = Artist, group = 1)) +
#   #geom_point(aes(alpha = 0.9)) +
#   geom_point(alpha = 0.2) +
#   geom_line(aes(y = mean_valence, group = 1, alpha = 0.1), color = "black") +
#   #geom_point(aes(y = mean_valence, alpha = 1)) +
#   geom_point(aes(y = mean_valence, group = 1), shape = 22, size = 2) +
#   labs(x = "Week") + theme_light()
# 
# # bscols(widths = c(2,5,5),
# #        list(fls,
# #             fls2,
# #             flc,
# #             flc2),
# #   ggplotly(p1),
# #   ggplotly(p2)
# # )
# 
# bscols(ggplotly(p1),
#        ggplotly(p2)
#        )


sd_corpus <- SharedData$new(corpus_df)
# fls <- filter_slider("week", "week_n", sd_corpus, "week", step = 1)
fls_1 <- filter_slider("ps", "Position", sd_corpus, "Position", step = 1)
fls_2 <- filter_slider("streams", "Streams", sd_corpus, "Streams", step = 100000)
flc_1 <- filter_checkbox(id = "pandemic", label = "Pandemic", sharedData = sd_corpus, group = ~pandemic, inline = TRUE)
flc_2 <- filter_checkbox(id = "week", label = "week_n", sharedData = sd_corpus, group = ~week_n, inline = TRUE)

p1 <- ggplot(sd_corpus, aes(x = valence, y = energy, colour = pandemic, label = `Track Name`, label2 = Artist)) +
  geom_point(aes(size = danceability), alpha = 0.3) +
  scale_color_viridis_d(
    alpha = 0.7,
    begin = 0.5,
    end = 0.9,
  ) +
  theme_light()

p2 <- ggplot(sd_corpus, aes(x = week, colour = pandemic, label = year, group = 1)) +
  geom_line(aes(y = mean_valence, group = 1, alpha = 0.1)) +
  geom_point(aes(y = mean_valence, group = 1), shape = 22, size = 2) +
  facet_grid(rows = vars(year)) +
  scale_color_viridis_d(
    alpha = 0.7,
    begin = 0.5,
    end = 0.9,
  ) +
  labs(x = "Week", y = "Average Valence") + theme_light()

p3 <- ggplot(sd_corpus, aes(x = week, colour = pandemic, label = year, group = 1)) +
  geom_line(aes(y = mean_streams, group = 1, alpha = 0.1)) +
  geom_point(aes(y = mean_streams, group = 1), shape = 22, size = 2) +
  facet_grid(rows = vars(year)) +
  scale_color_viridis_d(
    alpha = 0.7,
    begin = 0.5,
    end = 0.9,
  ) +
  labs(x = "Week", y = "Average Streams") + theme_light()


bscols(widths = c(6, 6),
       ggplotly(p1),
       list(
         ggplotly(p2),
         ggplotly(p3)
       ))

```

***

```{js, echo = FALSE}
function hideShow2() {
  var x = document.getElementById("divID2");
  if (x.style.display === "none") {
    x.style.display = "block";
  } else {
    x.style.display = "none";
  }
}
```

<button class="btn2" onclick="hideShow2()">Toggle Filter</button>

<div id="divID2">

`r bscols(list(fls_1,fls_2,flc_1,flc_2))`

</div>



***

In this frame you make week-for-week comparisons for different variables based on the period before or during the pandemic. 

The interesting variables to compare the different periods are *valence* and *energy* as these reflect the valance/arousal model that shows the emotions *Happy*, *Angry*, *Sad*, *Relaxed*. 

The corpus is spread fairly evenly, and both before and during the pandemic most of the Top 50 tracks are in the *Happy* quadrant. This is not very surprising, as the Top 50 usually mostly consist of pop songs.

In the weekly plots it is observed that the average valence is much higher during the pandemic. And that the average weekly streams follow a similar trend, with some anomalies. These will be explored further down the line. 

<!-- Frame 4 -->

### 4. Top streamed tracks: Consistent hits and one hit wonders. **Difficult to classify most popular song**<br>*Note: tentative*{data-commentary-width=500}  

```{r, echo = FALSE}
require(flexdashboard)
require(shinydashboard)
require(shiny)

top_tot_streams <- distinct(
  # traxjoin %>%
  comb_data_trax %>% 
    group_by(top_track) %>% 
    summarize(tot_streams, 
              number_weeks_top1 = n,
              avg_topstream_topweek = round((tot_streams/n), digits = 0),
              pandemic) %>% 
    arrange(desc(tot_streams))
  )

top_tot_streams_t <- top_tot_streams

names(top_tot_streams_t)[1] <- "Track name - Artist"
names(top_tot_streams_t)[2] <- "Total Streams"
names(top_tot_streams_t)[3] <- "Number of weeks at Top 1"
names(top_tot_streams_t)[4] <- "Average Streams per week on Top 1"

# top_table <- datatable(top_tot_streams_t)

sd_top_tot <- SharedData$new(top_tot_streams_t)
fls4_1 <- filter_slider("n_weeks", "Number of weeks at Top 1", sd_top_tot, "Number of weeks at Top 1", step = 1)
fls4_2 <- filter_slider("tot_streams", "Total Streams", sd_top_tot, "Total Streams", step = 100000)
fls4_3 <- filter_slider("avg_streams", "Average Streams per week on Top 1", sd_top_tot, "Average Streams per week on Top 1", step = 100000)
flc4_1 <- filter_checkbox(id = "pandemic", label = "pandemic", sharedData = sd_top_tot, group = ~pandemic, inline = TRUE)

# p_t <- ggplot(comb_data_trax, aes(x = max_streams, y = fct_rev(week_year), label = factor(paste(top_track, "|", n,
#                                                                                          "weeks")))) +
#   #geom_count(aes(size = n), group = 1, stat = "identity") +
#   geom_text(aes(color = factor(top_track))) + 
#   #geom_text(aes(color = n)) +
#   #geom_text(aes(label = paste(top_track, n))) +
#   #geom_line(aes(x = max_streams, y = fct_rev(week_year)), alpha = 0.05, group = 1, size = comb_data_trax$n) +
#   geom_point(alpha = 0.2) + 
#   theme_light()   
#   #scale_color_viridis_d()
#   #scale_color_viridis_c()
# 
# # tabBox(width=NULL,
# #        height = 1000,
# #        title = tagList(shiny::icon("virus"),shiny::icon("spotify"),"Top Tracks"),
# #        id = "tabset2",
# #        tabPanel("Top Streams", top_table),
# #        tabPanel("Top 1 Tracks per week", ggplotly(p_t, width = 1450, height = 725))
# #        )

tabBox(width=NULL,
       title = tagList(shiny::icon("virus"),shiny::icon("spotify"),"Top Tracks"),
       id = "tabset2",
       tabPanel("Top Streams", datatable(sd_top_tot))
       )

```

***

```{js, echo = FALSE}
function hideShow3() {
  var x = document.getElementById("divID3");
  if (x.style.display === "none") {
    x.style.display = "block";
  } else {
    x.style.display = "none";
  }
}
```

<button class="btn2" onclick="hideShow3()">Toggle Filter</button>

<div id="divID3">

`r bscols(list(fls4_1,fls4_2,fls4_3,flc4_1))`

</div>

In the corpus there are a total of **35 distinct tracks** topping that charts in a span of 112 weeks. On average a Top 1 track remains for `r mean(top_tot_streams$number_weeks_top1)` weeks on the number 1 spot, while streamed `r round(mean(top_tot_streams$tot_streams))` times, and `r round(mean(top_tot_streams$avg_topstream_topweek))` times per week on the Top 1 spot.

<h5>The most popular track</h5>
This gives an interesting insight to the weekly most popular songs in this corpus. But which track is the most popular? Since the corpus is time constrained, solely considering the number of streams might not show the full picture. Therefore, three variables are considered:

**1.	Total number of streams while on Top**
**2.	Number of weeks on Top**
**3.	Average streams while on Top per week on Top**

The most popular song according to **variable 1 is “Dance Monkey”** by Tones And I, with a total of **31,534,809 streams** while at number 1. The **other variables (v2 = 14 weeks | v3 = 2,252,486 per week)** show that **the track performs above average** and can indeed be considered popular, both before and during the pandemic.

According to **variable 2**, Dance Monkey again is the most popular. But at second place, we find **“Mood (feat. iann dior)” by 24kGoldn is the most popular**, topping the charts for a total of 9 weeks. The other variables (v1 = 15,498,940 | v3 = 1,722,104 per week) show that it is significantly popular under v1, but underperforms under v3, this track is popular during the pandemic.

Variable 3 shows that the Euroviosion winner “Arcade” by Duncan Laurence is streamed the most per week while on top with 4,274,571 streams. The track performs above average on v1, but underperforms under v3 (v1 = 8,549,142 | v2 = 2 weeks). Winning the Eurovision (before the pandemic) cause a huge spike, but was rather temporarily.

During the pandemic, according to v3, “Tigers” by Bilal Wahib is streamed the most per week while at the top with 2,652,339 streams. The track underperforms on the other variables (v1 = 5,304,679 | v2 = 2 weeks). Thus, this song can be considered a viral hit or more harshly a “one hit wonder” for two weeks.

There are limitations to this approach, as only the number one spots are considered. For a clearer picture, a wider range is recommended. Even considering these variables for these top songs, most perform very similarly. Thus, it remains difficult to denote which song is the most popular.

<!-- Frame 5 -->

### 5. 17 Miljoen Mensen vs. 15 Miljoen Mensen - The prominent cover song during the pandemic shows **little similarity with original**{data-commentary-width=500} 

```{r, include = FALSE}
## 17 Miljoen
miljoen_17 <-
  get_tidy_audio_analysis("7e42rjxCt8tPjglU9VyBcz") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

miljoen_17f <- get_track_audio_features("7e42rjxCt8tPjglU9VyBcz")

## 15 Miljoen
miljoen_15 <-
  get_tidy_audio_analysis("2GBJFvDr62eIX24a3t6pBr") %>%
  select(segments) %>%
  unnest(segments) %>%
  select(start, duration, pitches)

miljoen_15f <- get_track_audio_features("2GBJFvDr62eIX24a3t6pBr")

miljoen_17f <- as.data.frame(t(miljoen_17f))
miljoen_15f <- as.data.frame(t(miljoen_15f))
miljoen_f <- cbind(miljoen_17f,miljoen_15f)
miljoen_f <- miljoen_f[-(12:16),]
row.names(miljoen_f)[12] <- "duration_sec"
miljoen_f[12,] <- as.integer(miljoen_f[12,])/1000

names(miljoen_f) <- c("17 Miljoen Mensen (2020)", "15 Miljoen Mensen (1996)")

miljoen_17c <- miljoen_17 %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", subtitle = "17 Miljoen Mensen (2020)") +
  theme_minimal() +
  scale_fill_viridis_c()

miljoen_15c <- miljoen_15 %>%
  mutate(pitches = map(pitches, compmus_normalise, "euclidean")) %>%
  compmus_gather_chroma() %>% 
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = pitch_class,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", subtitle = "Chromagram/n15 Miljoen Mensen (1996)") +
  theme_minimal() +
  scale_fill_viridis_c()

miljoen_p <- compmus_long_distance(
  miljoen_15 %>% mutate(pitches = map(pitches, compmus_normalise, "euclidean")),
  miljoen_17 %>% mutate(pitches = map(pitches, compmus_normalise, "euclidean")),
  feature = pitches,
  method = "cosine"
) %>%
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_equal() +
  labs(x = "15 Milljoen mensen (1996)", y = "17 Miljoen mensen (2020)", subtitle = "Dynamic Time Warp/n17 miljoen mensen vs. 15 mijoen mensen") +
  theme_minimal() +
  scale_fill_viridis_c(guide = NULL)



```

```{r Plots, echo = FALSE}
miljoen_15cl <- miljoen_15c + theme(legend.position = "none")

grid.arrange(miljoen_p, # First row with one plot spanning over 2 columns
             arrangeGrob(miljoen_17c, miljoen_15cl, ncol = 2), # Second row with 2 plots in 2 different columns
             nrow = 2)  
```

***

<ul class="nav nav-tabs">
  <li class="nav-item">
    <a class="nav-link active" data-toggle="tab" href="#chroma">Chroma</a>
  </li>
  <li class="nav-item">
    <a class="nav-link" data-toggle="tab" href="#saf">Audio Features</a>
  </li>
</ul>


<div id="myTabContent" class="tab-content">
  <div class="tab-pane fade active in" id="chroma">

<h4>DTW and Chromagrams</h4>
The track "17 Miljoen Mensen" (2020) is a cover of "15 Miljoen Mensen" (1996). An analysis of the chromafeatures of the two tracks aims find similarities between them. Notice the d 17 Miljoen mensen's title adjustment for the population increase of 2 million people, and its shortness with a duration of just 1 minute and 47 seconds. But what are other differences or similarities?

The first plot shows the **Dynamic Time Warping** plot of the two tracks, using Euclidean norm and angular distance. A diagonal pattern would denote similarity between the two tracks. This is not observed, which implies **significant differences between the two tracks**. This is supported as the the table shows that the **pitch classes differ**. According to the Spotify API, **"17 Miljoen Mensen" is in the key of G major**, wheras **"15 Miljoen Mensen" is in the key of C major**. This is not explicitly shown, but they are represented in their respective chromagrams.

In addition, the 'sound and feel' of the tracks differ: 15 miljoen mensen has a higher danceability, energy, and loudness, whereas "17 miljoen mensen" has a much higher acousticness and liveness (due to the recording being a live performance).

A remarkable commonality probably explains the differences: Both tracks were unintended single releases, ["15 miljoen mensen" was initially written for a commercial, and "17 Miljoen mensen" as a tribute for a (due to COVID-19) canceled music concert](https://nl.wikipedia.org/wiki/15_miljoen_mensen){target="_blank"}. The different motivations behind the tracks reflects the different 'sound and feel' as shown by Spotify API.

For a commercial you would want a more catchy/upbeat track, contrary to a song related to a disaster or crisis. This explains the difference in **loundness**, **"15 Miljoen Mensen" has a loudness of -10.041dB**, wheras **"15 Miljoen Mensen" has a loudness of -7.063dB**.
  
  </div>
  
  <div class="tab-pane fade" id="saf">

<h4>Spotify Features Table</h4>

`r knitr::kable(miljoen_f)`

  </div>
</div>


***

```{=html}
<object data="https://open.spotify.com/embed/playlist/3wraxQVN9Z6PmTk7wEA6wR" width="280" height="80">
    <embed src="https://open.spotify.com/embed/playlist/3wraxQVN9Z6PmTk7wEA6wR" width="280" height="80"></embed>
    Error: Embedded data could not be displayed.
</object>
```



<!-- Frame 6 -->

### 6. All I Want *be*for*e* Christmas... is Christmas<br>**Earlier Christmas in 2020** due to the lockdown.

```{r, echo = FALSE}
# p <- ggplot(data2020, aes(mean_valence, mean_energy, size = mean_dance, color = mean_tempo, label = week_year))
# 
# ggplotly(p + geom_point())

z <- comb_data %>%
  filter(year...27 %in% c(2019, 2020)) %>%
  # filter(year %in% c(2019, 2020)) %>%  
  filter(week %in% c(45:53))

z_a <- z %>% 
  filter(year...27 == 2020) %>%
  filter(week %in% c(50:53))

ann_1 <- data.frame(mean_valence = 0.6,mean_energy = 0.5868,
                       year...27 = factor(2020,levels = c(2019,2020)),
                       top_track = "all i want")
ann_2 <- data.frame(mean_valence = 0.6,mean_energy = 0.5868,
                       year...27 = factor(2019,levels = c(2019,2020)),
                       top_track = "all i want")

#p <- ggplot(z, aes(mean_valence, mean_energy, color = mean_tempo, label = week_year, label2 = top_track)) +
p <- ggplot(z, aes(mean_valence, mean_energy, label = top_track)) +
  geom_point(aes(size = mean_dance, color = mean_tempo)) +
  geom_text(aes(label = week), vjust = 0, nudge_y = 0.003, nudge_x = 0.003) +
  facet_grid(. ~ year...27)+
  # facet_grid(. ~ year)+
  scale_colour_viridis_c(
    option = "D",
    alpha = 0.75,
  ) +
  theme_light() +
  labs(
    x = "Mean Valence",
    y = "Mean Energy",
    title = "Audio features per week in 2019 and 2020",
    subtitle = "Christmas music increases average valence and decreases average energy in Top 50 playlist"
  )

p1 <- p + 
  #geom_point(ann_1, mapping = aes(mean_valence, mean_energy), size = 35, alpha = 0.03) +
  geom_text(ann_1, mapping =  aes(x=0.57, y=0.57, label="<i>All I Want for Christmas Is You</i>", check_overlap = TRUE)) +
  geom_text(ann_2, mapping =  aes(x=0.57, y=0.558, label="<i>All I Want for Christmas Is You</i>", check_overlap = TRUE))

p1 <- p1 + stat_ellipse(mapping = aes(mean_valence, mean_energy), data = z_a, linetype = 1)

ggplotly(p1)
   
```

***

**Christmas songs started to dominate the charts in 2020 from around week 49 until week 53**, whereas **in 2019 Christmas this phenomenon occurred a bit later**. In 2020 it is noticeable that the bottom right corner contain tracks with *relatively* high BPM, high valence, lower energy and lower danceability.During these weeks Christmas tracks dominated the charts. **In 2019 this phenomenon is very noticeable in week 52**, but shows that Christmas slowly started in week 50. Also in 2020, the charts remained similar during the holiday period from week 50 to 53, whereas in 2019 week 52 saw a spike of the Christmas related audio features. This pattern implies more Christmas tracks entered the Top 50.

Interestingly, Mariah Carey's 'All I Want for Christmas' topped the charts for four consecutive weeks in 2020, as opposed to 1 week in 2019.

A Possible explanation is that due to the imposed lockdown and other restrictions, people may have felt a need or desire for the "Christmas Spirit/Vibes" a week earlier than in 2019.

Another interesting discovery is that similar to 2019, the top streams in 2020 decreased in similar fashion. A possible explanation is that people disregarded the lockdown regulations and spent the holiday season with friends and/or family or were preoccupied with other activities to keep in touch with them.

<!-- Frame 7 -->

### 7. Self-Similarity Matrix: "Dance Monkey" **Shows repeating pattern and noticeably distinct Millennial Whoop** {data-commentary-width=500} 
```{r, include = FALSE}
dancemonkey <-
  get_tidy_audio_analysis("1rgnBhdG2JDFTbYkYRZAku") %>% # Change URI.
  compmus_align(bars, segments) %>%                     # Change `bars`
  select(bars) %>%                                      #   in all three
  unnest(bars) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "mean", norm = "euclidean"              # Change summary & norm.
      )
  )
```


```{r, include = FALSE}
# Cepstrogram
cep <- dancemonkey %>%
  compmus_gather_timbre() %>%
  ggplot(
    aes(
      x = start + duration / 2,
      width = duration,
      y = basis,
      fill = value
    )
  ) +
  geom_tile() +
  labs(x = "Time (s)", y = NULL, fill = "Magnitude", title = "Dance Monkey - Tones And I", subtitle = "Cepstrogram: Timbre") +
  scale_fill_viridis_c() +                              
  theme_classic()
```

```{r, include = FALSE}
# Self-Similarity Matrix Pitch
ssm_p <- dancemonkey %>%
  compmus_self_similarity(pitches, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  geom_vline(xintercept = 50, size=1) +
  geom_vline(xintercept = 69, size=1, alpha = 0.5) +
  geom_vline(xintercept = 111, size=1) +
  geom_vline(xintercept = 147, color = "red", size=1) +
  geom_vline(xintercept = 167, color = "red", size=1) +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "Time (s)", y = "Time (s)", subtitle = "SSM: Pitch")
```

```{r, include = FALSE}
# Self-Similarity Matrix Timbre
ssm_t <- dancemonkey %>%
  compmus_self_similarity(timbre, "euclidean") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  geom_vline(xintercept = 50, size=1) +
  geom_vline(xintercept = 69, size=1, alpha = 0.5) +
  geom_vline(xintercept = 111, size=1) +
  geom_vline(xintercept = 147, color = "red", size=1) +
  geom_vline(xintercept = 167, color = "red", size=1) +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "Time (s)", y = "", subtitle = "SSM: Timbre")
```

```{r, echo = FALSE}
# grid.arrange(cep, # First row with one plot spanning over 2 columns
#              arrangeGrob(ssm_p, ssm_t, ncol = 2), # Second row with 2 plots in 2 different columns
#              nrow = 2)

    cep /
(ssm_p | ssm_t)
```

***

##### Dance Monkey
“Dance Monkey” by Tones And I is one of the most popular tracks within the corpus. A structure analysis will show possible patterns of sequences within the track and their relation.

##### Cepstrogram
The first cepstrogram plot shows the magnitude of each timbre feature per segment of the track. The feature c01 is loudness, c02 is low frequency, c03 is mid frequencies. c04 and up are not defined as straight forward, but they may be implied by keeping track of changes within a track during specific segments. The cepstrogram shows that "Dance Monkey’s timbre features are relatively more defined by c01 to c05.

- **c01 Loudness:** The segments reflect the loudness of the track, this is especially noted during the final chorus.
- **c02 Darkness:** The segments faintly show a higher magnitude when the bass drum hits. But its omission is noted much clearly during the breakdown starting at 150 seconds.
- **c03 Mid frequency:** It's shown at about 50 seconds and 165 seconds when higher notes are less and more distinct respectively.
- **c04 Attack:** This is very prevalent during the intro (vocal stretch fade-in sfx).
- **c05 [Unknown]:** It has the highest magnitude at around 150 seconds, noticeable is the loudness of the "[Millenial Whoop](https://en.wikipedia.org/wiki/Millennial_whoop){target="_blank"}".

##### Self Similarity
The second and third plots are Self Similarity Matrices (SSM); The first being pitch, and the second timbre. These plots show the structure of a track by denoting patterns of similarities that reoccur. Diagonal lines and a checkerboard pattern show similarity and repetition.

The timbre SSM is plotted using Euclidean norm, Euclidean distance and summarized by the mean. The plot shows a faint checkerboard pattern which implies some form of repetition in the track. At the 150 second mark there is a significant timbre difference. This is when the breakdown occurs with the earlier mentioned “Millenial Whoop”.

The pitch SSM is plotted using Euclidean norm, cosine distance and summarized by root mean square. This plot shows a slightly more noticeable checkerboard pattern. At the 150 second mark, the plot shows a significant change.

***

```{=html}
<object data="https://open.spotify.com/embed/track/1rgnBhdG2JDFTbYkYRZAku" width="280" height="80">
    <embed src="https://open.spotify.com/embed/track/1rgnBhdG2JDFTbYkYRZAku" width="280" height="80"></embed>
    Error: Embedded data could not be displayed.
</object>
```



<!-- Frame 8 -->

### 8. In the *mood* for which keys?<br>Chord and Key estimations for *"Mood"*.

```{r, echo = FALSE}

mood <-
  get_tidy_audio_analysis("3tjFYV6RSFtuktYl3ZtYcq") %>%
  compmus_align(bars, segments) %>%
  select(bars) %>%
  unnest(bars) %>%
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"
      )
  )

mk <- mood %>% 
  compmus_match_pitch_template(
    key_templates,         # Change to chord_templates if descired
    method = "cosine",  # Try different distance metrics
    norm = "euclidean"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  #scale_fill_viridis_c(guide = "none") +
  scale_fill_viridis_c() +
  theme_minimal() +
  labs(x = "Time (s)", y = "", fill = "d", title = "Mood (feat. iann dior) - 24kGoldn", subtitle = "Keygram")

mc <- mood %>% 
  compmus_match_pitch_template(
    chord_templates,         # Change to chord_templates if desired
    method = "cosine",  # Try different distance metrics
    norm = "euclidean"     # Try different norms
  ) %>%
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)
  ) +
  geom_tile() +
  #scale_fill_viridis_c(guide = "none") +
  scale_fill_viridis_c() +
  theme_minimal() +
  labs(x = "Time (s)", y = "", fill = "d", title = " ", subtitle = "Chordogram")

grid.arrange(
  arrangeGrob(
    mk,
    mc,ncol = 2),
  nrow = 1)

```

***

The track *Mood* by 24kGoldn ft. iann diorr is also one of the identified popular tracks in the corpus.
A keygram and chordogram are plotted in order to show the tonal progression of the track by estimating the chords and key for each segment.

The keygram shows that the key *E♭ major, G minor, F major, C major, G major*, and *C♯minor* are prevalent keys during the track.
The Chordogram show that the chords *C minor, E♭ 7, and E♭ major* are the most prevalent chords of the track. 

**Spotify API**

According to the [Spotify API](https://developer.spotify.com/documentation/web-api/reference/#object-audiofeaturesobject){target="_blank"}, this track is written in the 7th key,  with mode 0: meaning G minor.

**Chordify**

The [Chordify algorithm](https://chordify.net/chords/24kgoldn-mood-official-video-ft-iann-dior-24kgoldnvevo){target="_blank"} identified the chords within the following (4/4) loop:

| E♭ - Gm - | B♭ - F - |


The identified key appears to be on the natural scale:

G - A - B♭ - C - D - E♭ - F

***

```{=html}
<object data="https://open.spotify.com/embed/track/3tjFYV6RSFtuktYl3ZtYcq" width="280" height="80">
    <embed src="https://open.spotify.com/embed/track/3tjFYV6RSFtuktYl3ZtYcq" width="280" height="80"></embed>
    Error: Embedded data could not be displayed.
</object>
```



<!-- Frame 9 -->

### 9. Histogram of Keys within the corpus shows **C♯** as the most common key.


```{r, echo = FALSE}
pc <- corpus_df %>%
  group_by(year) %>%
  summarize(key, mode = recode_factor(mode,
                              `0` = as.character("Minor"),
                              `1` = as.character("Major"))) %>%
  mutate(key_key = recode_factor(key,
                              `0` = as.character("C"),
                              `1` = as.character("C\U266F\nD\U266D"),
                              `2` = as.character("D"),
                              `3` = as.character("D\U266F\nE\U266D"),
                              `4` = as.character("E"),
                              `5` = as.character("F"),
                              `6` = as.character("F\U266F\nG\U266D"),
                              `7` = as.character("G"),
                              `8` = as.character("G\U266F\nA\U266D"),
                              `9` = as.character("A"),
                              `10` = as.character("A\U266F\nB\U266D"),
                              `11` = as.character("B")))
    # mutate(key_key = recode_factor(key,
    #                           `0` = "C",
    #                           `1` = "C#",
    #                           `2` = "D",
    #                           `3` = "D#",
    #                           `4` = "E",
    #                           `5` = "F",
    #                           `6` = "F#",
    #                           `7` = "G",
    #                           `8` = "G#",
    #                           `9` = "A",
    #                           `10` = "A#",
    #                           `11` = "B")) %>%
p9_1 <- pc %>%  
ggplot(aes(x = key_key, fill = as.factor(mode))) +
  facet_wrap(~ year) +
  scale_fill_viridis_d(
    alpha = 0.7,
    begin = 0.6,
    end = 0.9,
    option = "D",
    name = "Mode",
    labels = c("Minor", "Major")
  ) +
  labs(
    x = "Key",
    title = "Key frequency in corpus per year",
    subtitle = "") +
  theme_light() +
  geom_histogram(stat = "count")

p9_2 <- pc %>%  
ggplot(aes(x = key_key, fill = as.factor(mode))) +
  facet_wrap(~ year) +
  scale_fill_viridis_d(
    alpha = 0.7,
    begin = 0.6,
    end = 0.9,
    option = "D",
    name = "Mode",
    labels = c("Minor", "Major")
  ) +
  labs(
    x = "Key",
    y = "Density",
    title = "Normalized key occurrences in corpus per year",
    subtitle = "") +
  theme_light() +
  #geom_histogram(aes(y=..count../sum(..count..)), stat = "count", alpha=0.6, position="identity")
  geom_histogram(aes(y=(..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..]), stat = "count") #+
  #scale_y_continuous(labels=percent_format())

ply9_1 <- ggplotly(p9_1, width = 1050, height = 525)
ply9_2 <- ggplotly(p9_2, width = 1050, height = 525)

#knitr::include_graphics("figure/hist.png")

```

```{r, echo = FALSE}
tabBox(width=NULL,
       height = 1000,
       title = tagList(shiny::icon("music"),"Key frequencies"),
       id = "tabset2",
       tabPanel("Normalized key ocurrences", ply9_2),
       tabPanel("key counts", ply9_1)
       )
```

***

While histogram doesn't show a clear/unanimous preference, the keys **C♯, F♯, G♯** consistently do have a relative high count within the corpus.

In 2019, There is a clear significant higher count of **C♯, F, G, B** keys.

In 2020, The keys **C♯, F♯, G♯, B** have a significantly higher frequency in the corpus.

Note that 2021 only contains the first 7 weeks, whereas 2019 and 2020 contain 52 and 53 weeks respectively. Therefore, its not very representative to make the most informed comparisons.

<!-- Frame 10 -->

### 10. Most prevalent beats:<br>Tempi around **100 BPM** and **120 BPM** most common in corpus.

```{r, echo = FALSE}
pc <- corpus_df %>%
  group_by(year) %>%
  summarize(tempo, mode = recode_factor(mode,
                              `0` = as.character("Minor"),
                              `1` = as.character("Major")))
p10_1 <- pc %>%  
#ggplot(aes(x = key_key, fill = as.factor(mode))) +
ggplot(aes(x = tempo, fill = year)) +
  #facet_wrap(~ year...31) +
  scale_fill_viridis_d(
    alpha = 0.7,
    begin = 0.2,
    end = 0.9,
    option = "D",
    name = "Year",
    # labels = c("Minor", "Major")
  ) +
  labs(
    x = "BPM",
    title = "Tempo frequency in corpus",
    subtitle = "") +
  theme_light() +
  scale_x_continuous(breaks = seq(40, 210, by = 20)) +
  #geom_histogram(stat = "count")
  geom_density(alpha = 0.475)

# p9_2 <- pc %>%  
# ggplot(aes(x = key_key, fill = as.factor(mode))) +
#   facet_wrap(~ year...31) +
#   scale_fill_viridis_d(
#     alpha = 0.7,
#     begin = 0.6,
#     end = 0.9,
#     option = "D",
#     name = "Mode",
#     labels = c("Minor", "Major")
#   ) +
#   labs(
#     x = "Key",
#     y = "Density",
#     title = "Normalized key occurrences in corpus per year",
#     subtitle = "") +
#   theme_light() +
#   #geom_histogram(aes(y=..count../sum(..count..)), stat = "count", alpha=0.6, position="identity")
#   geom_histogram(aes(y=(..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..]), stat = "count") #+
#   #scale_y_continuous(labels=percent_format())
# 
# ply1_1 <- ggplotly(p9_1, width = 1050, height = 525)
# ply9_2 <- ggplotly(p9_2, width = 1050, height = 525)

#knitr::include_graphics("figure/hist.png")

# ply10_1 <- 
  
ggplotly(p10_1)

averageBPM <- corpus_df %>%
  summarize(mean_tempo = mean(tempo))

# vb10 <- flexdashboard::valueBox(round(averageBPM$mean_tempo), icon="fa-music")

# grid.arrange(
#   arrangeGrob(
#     ply10_1,
#     vb10,ncol = 2),
#   nrow = 1)
```

***

The density plot shows that overall the the most frequent tempi within the corpus is around 90-100 BPM and 115-128 BPM.
The year **2019** showed a strong preference for tracks around **98 BPM** and to a lesser extent **123 BPM**.

The year **2020** showed a strong preference for tracks around both **95 BPM** and **121 BPM**.

The first **7 weeks of 2021** showed a preference for tracks around **99 BPM** and **122 BPM**.


***

**Average Tempo:**

```{js, echo = FALSE}
var divs = ["id2019", "id2020", "id2021"];
var visibleDivId = null;

function toggleVisibility(divId) {
  if (visibleDivId === divId) {
    visibleDivId = null;
  } else {
    visibleDivId = divId;
  }

  hideNonVisibleDivs();
}

function hideNonVisibleDivs() {
  var i, divId, div;

  for (i = 0; i < divs.length; i++) {
    divId = divs[i];
    div = document.getElementById(divId);

    if (visibleDivId === divId) {
      div.style.display = "block";
    } else {
      div.style.display = "none";
    }
  }
}
```

```{=html}
<div class="storyboard-nav">
  <div class="sbframelist" style="overflow: hidden;width: 100%;">
    <ul style="transform: translateZ(0px); width: 270px;">
      <li id="id2019" class="box"><h2>117</h2><h4>BPM</h4></li>
      <li id="id2020" class="box"><h2>116</h2><h4>BPM</h4></li>
      <li id="id2021" class="box"><h2>121</h2><h4>BPM</h4></li>
    </ul>
  </div>    
</div>
<div>
  <button class="btn1 b2019" onclick="toggleVisibility('id2019')">2019</button>
  <button class="btn1 b2020" onclick="toggleVisibility('id2020')">2020</button>
  <button class="btn1 b2021" onclick="toggleVisibility('id2021')">2021</button>
</div>



<!-- <button class="btn1 b2019" onclick="toggleVisibility('2019')">2019</button> -->
<!-- <button class="btn1 b2020" onclick="toggleVisibility('2020')">2020</button> -->
<!-- <button class="btn1 b2021" onclick="toggleVisibility('2021')">2021</button> -->
```
*Press one of these buttons to display the average BPM*


<!-- Frame 11 -->

### 11. *"Tigers"* by Bilal Wahib has a tempo of **112 BPM**

```{r, include = FALSE, cache = TRUE}
tiger <- get_tidy_audio_analysis("7jnaow1bGpKO2VkgtYE8Vv")

p11_1 <- tiger %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = FALSE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(title = "Tempogram", subtitle = "Tigers - Bilal Wahib",  x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()


p11_2 <- tiger %>%
  tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) %>%
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(title = "Tempogram (cyclic)", subtitle = "Tigers - Bilal Wahib", x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()

```

```{r, echo=FALSE}
# px_1 <- xmlSVG({show(p11_1)}, standalone = TRUE)
# 
# px_2 <- xmlSVG({show(p11_2)}, standalone = TRUE)
# 
# slickR(list(px_1, px_2), height = 200, width = "95%")

settings <- settings(dots = TRUE, adaptiveHeight = FALSE)

plist <- list("Rplot1.png", "Rplot2.png")

slickR(plist, height = "80", width = "80%") + settings

```

***

Another popular track in the corpus is "Tigers" by Bilal Wahib. Tempograms are plotted in order to show the estimated BPM of the track along its duration.

The *tempo* feature of the Spotify API estimates a **BPM of 111.943** (rounded 112 BPM).

The first Tempogram doens't explicitly reflect the estimation of the Spotify API, tempi of around 210-220 and 430-450 are shown in the plot. The plot might record the represent half-time and quarter time BPM's of 224 and 448 (based on the estimation of 112 BPM).

The second Tempogram (cyclic), is adjusted to represent the more 'common' tempi at which humans tap. This plot does reflect the Spotify API estimation of 112 BPM more clearly.

At the 75 second mark, there is a slight drop and increase in tempo. From this point, noticeable is the tape stop sound effect, which is immediately followed by the bridge. The BPM however, remains the same (try to tap along).

***

```{=html}
<object data="https://open.spotify.com/embed/track/7jnaow1bGpKO2VkgtYE8Vv" width="280" height="80">
    <embed src="https://open.spotify.com/embed/track/7jnaow1bGpKO2VkgtYE8Vv" width="280" height="80"></embed>
    Error: Embedded data could not be displayed.
</object>
```
<!-- Frame 12 -->

### Trees and Neighbors: Applying machine learning model on corpus show there *is* a **difference between the pre-pandemic and intra-pandemic periods**.

```{r, include = FALSE, cache = TRUE}
corpus_cf <- corpus_top25 %>%
    add_audio_analysis()
```

```{r, include = FALSE, cache = TRUE}
corpus_features <-
    # #corpus_top10 %>%  # For your portfolio, change this to the name of your corpus.
    # corpus_df %>%  # For your portfolio, change this to the name of your corpus.
    # add_audio_analysis() %>%
    corpus_cf %>%
    mutate(
        pandemic = factor(pandemic),
        segments = map2(segments, key, compmus_c_transpose),
        pitches =
            map(
                segments,
                compmus_summarise, pitches,
                method = "mean", norm = "manhattan"
            ),
        timbre =
            map(
                segments,
                compmus_summarise, timbre,
                method = "mean",
            )
    ) %>%
    mutate(pitches = map(pitches, compmus_normalise, "clr")) %>%
    mutate_at(vars(pitches, timbre), map, bind_rows) %>%
    unnest(cols = c(pitches, timbre))
```

```{r, include = FALSE, cache = TRUE}
corpus_recipe <-
  recipe(
    pandemic ~
      danceability +
      energy +
      loudness +
      speechiness +
      acousticness +
      instrumentalness +
      liveness +
      valence +
      tempo +
      duration_minute +
      Streams +
      C + `C#|Db` + D + `D#|Eb` +
      E + `F` + `F#|Gb` + G +
      `G#|Ab` + A + `A#|Bb` + B +
      c01 + c02 + c03 + c04 + c05 + c06 +
      c07 + c08 + c09 + c10 + c11 + c12,
    data = corpus_features,          # Use the same name as the previous block.
  ) %>%
  step_center(all_predictors()) %>%
  step_scale(all_predictors())      # Converts to z-scores.
  # step_range(all_predictors())    # Sets range to [0, 1].
```

```{r, include=FALSE, cache = TRUE}
corpus_cv <- corpus_features %>% vfold_cv(10)

knn_model <-
  nearest_neighbor(neighbors = 1) %>%
  set_mode("classification") %>% 
  set_engine("kknn")
corpus_knn <- 
  workflow() %>% 
  add_recipe(corpus_recipe) %>% 
  add_model(knn_model) %>% 
  fit_resamples(
    corpus_cv, 
    control = control_resamples(save_pred = TRUE)
  )
``` 

```{r, include=FALSE, cache = TRUE}
tree_model <-
  decision_tree() %>%
  set_mode("classification") %>% 
  set_engine("C5.0")
corpus_tree <- 
  workflow() %>% 
  add_recipe(corpus_recipe) %>% 
  add_model(tree_model) %>% 
  fit_resamples(
    corpus_cv, 
    control = control_resamples(save_pred = TRUE)
  )
``` 

```{r, echo= FALSE}
#corpus_knn %>% get_conf_mat()
# corpus_knn %>% get_conf_mat() %>% autoplot(type = "mosaic")
#corpus_knn %>% get_conf_mat() %>% autoplot(type = "heatmap")
# corpus_tree %>% get_pr()

settings <- settings(dots = TRUE, adaptiveHeight = FALSE)

plist <- list("plot1.png", "plot2.png", "plot3.png")

slickR(plist, height = "80", width = "80%") + settings
```

***

The data has been heavily shrunk in order to run the machine learning algorithms without crashing. A subset of the data containing the top 3 tracks per week are selected. This totals 336 observations that will be split across the pandemic period. This makes is possible for the algorithm to predict whether a track belongs either in the period prior COVID-19 or during. A ten fold cross validation is used.

<h4>Confusion matrix</h4>
The Confusion matrix show the accuracy of the algorithm predicting classifiers. In this portfolio we'd like to find out wheter we can classify songs that belong to in the period prior or during the pandemic.

<h4>Random forest</h4>
The random forest ranks the importance of the different features that can be attributed to the classification of the songs. In this case we find that the variables ***Streams, G, c06, G#|Ab, B*** are the most important in this corpus.

`r knitr::kable(corpus_tree %>% get_pr())`

`r knitr::kable(corpus_knn %>% get_pr())`

```{r, include = FALSE, cache = TRUE}
# # USED
# 
# forest_model <-
#   rand_forest() %>%
#   set_mode("classification") %>% 
#   set_engine("ranger", importance = "impurity")
# corpus_forest <- 
#   workflow() %>% 
#   add_recipe(corpus_recipe) %>% 
#   add_model(forest_model) %>% 
#   fit_resamples(
#     corpus_cv, 
#     control = control_resamples(save_pred = TRUE)
#   )
```

```{r, echo=FALSE}
# #Used
# 
# workflow() %>% 
#   add_recipe(corpus_recipe) %>% 
#   add_model(forest_model) %>% 
#   fit(corpus_features) %>% 
#   pluck("fit", "fit", "fit") %>%
#   ranger::importance() %>% 
#   enframe() %>% 
#   mutate(name = fct_reorder(name, value)) %>% 
#   ggplot(aes(name, value)) + 
#   geom_col() + 
#   coord_flip() +
#   theme_minimal() +
#   labs(x = NULL, y = "Importance")
```

```{r, include=FALSE, cache = TRUE}
# corpus_features %>%
#   ggplot(aes(x = c01, y = c07, colour = pandemic, size = tempo)) +
#   geom_point(alpha = 0.8) +
#   scale_color_viridis_d() +
#   labs(
#     x = "Timbre Component 1",
#     y = "Timbre Component 7",
#     size = "Tempo",
#     colour = "Year"
#   )
``` 


```{r, include=FALSE}
# corpus_juice <-
#   recipe(
#     `Track Name` ~
#       danceability +
#       energy +
#       loudness +
#       speechiness +
#       acousticness +
#       instrumentalness +
#       liveness +
#       valence +
#       tempo +
#       duration_minute, # +
#       # C + `C#|Db` + D + `D#|Eb` +
#       # E + `F` + `F#|Gb` + G +
#       # `G#|Ab` + A + `A#|Bb` + B +
#       # c01 + c02 + c03 + c04 + c05 + c06 +
#       # c07 + c08 + c09 + c10 + c11 + c12,
#     data = corpus_top10
#   ) %>%
#   step_center(all_predictors()) %>%
#   step_scale(all_predictors()) %>% 
#   # step_range(all_predictors()) %>% 
#   prep(corpus_top10 %>% mutate(track.name = str_trunc(`Track Name`, 20))) %>%
#   juice() %>%
#   column_to_rownames("Track Name")
# 
# corpus_dist <- dist(corpus_juice, method = "euclidean")
# 
# corpus_dist %>% 
#   hclust(method = "single") %>% # Try single, average, and complete.
#   dendro_data() %>%
#   ggdendrogram()
```

<!-- Frame 14 -->

```{r, include = FALSE, cache = TRUE}
# workflow() %>% 
#   add_recipe(corpus_recipe) %>% 
#   add_model(forest_model) %>% 
#   fit(corpus_features) %>% 
#   pluck("fit", "fit", "fit") %>%
#   ranger::importance() %>% 
#   enframe() %>% 
#   mutate(name = fct_reorder(name, value)) %>% 
#   ggplot(aes(name, value)) + 
#   geom_col() + 
#   coord_flip() +
#   theme_minimal() +
#   labs(x = NULL, y = "Importance")
```

```{r, echo=FALSE}
# corpus_features %>%
#   ggplot(aes(x = c06, y = c10, colour = pandemic, size = Streams)) +
#   geom_point(alpha = 0.8) +
#   scale_color_viridis_d() +
#   labs(
#     x = "Timbre Component 6",
#     y = "Timbre Component 10",
#     size = "Number of Streams",
#     colour = "Pandemic period"
#   )
``` 


```{r, include=FALSE}
# corpus_juice <-
#   recipe(
#     `Track Name` ~
#       danceability +
#       energy +
#       loudness +
#       speechiness +
#       acousticness +
#       instrumentalness +
#       liveness +
#       valence +
#       tempo +
#       duration_minute, # +
#       # C + `C#|Db` + D + `D#|Eb` +
#       # E + `F` + `F#|Gb` + G +
#       # `G#|Ab` + A + `A#|Bb` + B +
#       # c01 + c02 + c03 + c04 + c05 + c06 +
#       # c07 + c08 + c09 + c10 + c11 + c12,
#     data = corpus_top10
#   ) %>%
#   step_center(all_predictors()) %>%
#   step_scale(all_predictors()) %>% 
#   # step_range(all_predictors()) %>% 
#   prep(corpus_top10 %>% mutate(track.name = str_trunc(`Track Name`, 20))) %>%
#   juice() %>%
#   column_to_rownames("Track Name")
# 
# corpus_dist <- dist(corpus_juice, method = "euclidean")
# 
# corpus_dist %>% 
#   hclust(method = "single") %>% # Try single, average, and complete.
#   dendro_data() %>%
#   ggdendrogram()
```

### End of the road: **Long term pandemic *does* have impact, but short term.** Not enough to change listening behavior.

<h4>Conclusion</h4>

We've seen that the pandemic did have a significant effect on society. 
This was also reflected in the spikes of the number of streams for *specific tracks*, explicitly shown in the earlier plots by the following.
- Togetherness and solidarity at the *beginning* of the pandemic
- Earlier and longer Christmas

We've seen that Dutch spotify users have a relative **quick reaction time** for a **short period**, this holds for the periods **before and during the pandemic**. This was clearly seen in the *Eurovision* and *17 Miljoen Mensen* examples. This has hasn't changed, this is also reflected that the subsequent coronawaves did not meet similar solidarity as the first. 

However on average, the number streams remained fairly stable.
Although similar to prior to the pandemic, we did find that people listened a bit more to 'happier' music. Interestingly this phenomenon combined with the fact the people tend to be "*coronamoe/corona fatigue*" [explains that people in the Netherlands are happier despite the pandemic](https://www.volkskrant.nl/nieuws-achtergrond/zijn-we-corona-moe-vast-toch-zijn-meer-nederlanders-blijer-met-hun-leven-dan-in-2019~b52dc4d7/){target="_blank"}.

All in all it can be concluded that the pandemic did have an impact, but at the same time the Dutch are quick to move on.

